{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"data\"\n",
    "export_dir = os.path.join(base_dir, \"export\")\n",
    "html_dir = os.path.join(base_dir, \"html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Labelstudio Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(export_dir, \"export_1.json\"), \"r\") as fin:\n",
    "    export = json.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Fonduer Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARALLEL = 6  # assuming a quad-core machine\n",
    "ATTRIBUTE = \"jobs_companie\"\n",
    "conn_string = 'postgresql://user@127.0.0.1:8001/' + ATTRIBUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine('postgresql://user@127.0.0.1:8001/')\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.execute(\"commit\")\n",
    "# conn.execute(\"create database \"+ATTRIBUTE)\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-19 10:19:48,236][INFO] fonduer.meta:49 - Setting logging directory to: logs/2022-04-19_10-19-48\n",
      "[2022-04-19 10:19:48,237][INFO] fonduer.meta:134 - Connecting user:user to 127.0.0.1:8001/jobs_companie\n",
      "[2022-04-19 10:19:48,746][INFO] fonduer.meta:162 - Initializing the storage schema\n"
     ]
    }
   ],
   "source": [
    "from fonduer import Meta, init_logging\n",
    "\n",
    "# Configure logging for Fonduer\n",
    "init_logging(log_dir=\"logs\")\n",
    "\n",
    "session = Meta.init(conn_string).Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.parser.preprocessors import HTMLDocPreprocessor\n",
    "from fonduer.parser import Parser\n",
    "\n",
    "# docs_path = 'data/html/'\n",
    "# # pdf_path = 'data/pdf/'\n",
    "\n",
    "# max_docs = 100\n",
    "# doc_preprocessor = HTMLDocPreprocessor(docs_path, max_docs=max_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_parser = Parser(session, structural=True, lingual=True)#, visual=True)#, pdf_path=pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_parser.apply(doc_preprocessor, parallelism=PARALLEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 5\n",
      "Sentences: 578\n"
     ]
    }
   ],
   "source": [
    "from fonduer.parser.models import Document, Sentence\n",
    "\n",
    "print(f\"Documents: {session.query(Document).count()}\")\n",
    "print(f\"Sentences: {session.query(Sentence).count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = session.query(Document).order_by(Document.name).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fonduer\n",
    "from bs4 import BeautifulSoup  # type: ignore\n",
    "from lxml import etree  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(label_studio_str: str):\n",
    "    split = label_studio_str.split(\"-\")  # strip id\n",
    "    full = \"\".join(split[1:])\n",
    "    split = full.split(\".\")\n",
    "    result = \"\".join(split[:-1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_tree_from_string(html_string):\n",
    "    soup = BeautifulSoup(html_string)\n",
    "    dom = etree.HTML(str(soup))\n",
    "    root = dom.getroottree()\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absolute_xpath(rel_xpath, dom):\n",
    "    res = dom.xpath(\"/\"+rel_xpath)[0]\n",
    "    return dom.getpath(res.getparent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_export(ls_export):\n",
    "    with open(ls_export, \"r\") as fin:\n",
    "        export = json.load(fin)\n",
    "    \n",
    "    for i, annotated_doc in enumerate(export):\n",
    "        tree = get_html_tree_from_string(annotated_doc[\"data\"][\"text\"])  # recreate html tree for doc\n",
    "\n",
    "        for j, annotations in enumerate(annotated_doc[\"annotations\"]):\n",
    "            if not annotations[\"result\"]:  # no annotations\n",
    "                continue\n",
    "            for k, entety in enumerate(annotations[\"result\"]):\n",
    "                if entety.get(\"value\"):\n",
    "                    xpath_rel = entety[\"value\"][\"start\"]\n",
    "                    text = entety[\"value\"][\"text\"]\n",
    "\n",
    "                    xpath_abs = get_absolute_xpath(xpath_rel, tree)\n",
    "\n",
    "                    export[i][\"annotations\"][j][\"result\"][k][\"value\"][\n",
    "                        \"start_abs\"\n",
    "                    ] = xpath_abs\n",
    "\n",
    "    return export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fin = parse_export(os.path.join(export_dir, \"export_1.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_docs={}\n",
    "for annotated_doc in exp_fin:\n",
    "    filename = get_filename(annotated_doc[\"file_upload\"])\n",
    "    fonduer_doc_id = str(session.query(Document.id).filter(Document.name==filename).first()[0])\n",
    "\n",
    "    doc = {}\n",
    "    doc[\"filename\"] = filename\n",
    "    doc[\"fonduer_doc_id\"] = fonduer_doc_id\n",
    "    doc[\"spots\"] = []\n",
    "\n",
    "    for annotations in annotated_doc[\"annotations\"]:\n",
    "        if not annotations[\"result\"]:\n",
    "            continue\n",
    "        for entety in annotations[\"result\"]:\n",
    "            if entety.get(\"value\"):\n",
    "                xpath_abs = entety[\"value\"][\"start_abs\"]\n",
    "                text = entety[\"value\"][\"text\"]\n",
    "                \n",
    "                sentence = session.query(Sentence).filter(Sentence.document_id==fonduer_doc_id, Sentence.xpath==xpath_abs).first()\n",
    "                assert text.replace(\"\\\\n\", \"\") in sentence.text\n",
    "                \n",
    "                xpath = entety[\"value\"][\"start\"]\n",
    "                label = entety[\"value\"][\"labels\"]\n",
    "                \n",
    "                doc[\"spots\"].append({\"xpath\": xpath, \"label\":label, \"text\":text, \"fonduer_sentence_id\":sentence.id})\n",
    "\n",
    "\n",
    "    labeled_docs[filename]=doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = {}\n",
    "for doc in labeled_docs:\n",
    "    idx = labeled_docs[doc][\"fonduer_doc_id\"]\n",
    "    patch[idx]={}\n",
    "    for spot in labeled_docs[doc][\"spots\"]:\n",
    "        if spot[\"label\"][0] not in patch[idx]:\n",
    "            patch[idx][spot[\"label\"][0]]={}\n",
    "            \n",
    "        fonduer_sentence_id = str(spot[\"fonduer_sentence_id\"])\n",
    "        text = spot[\"text\"].replace(\"\\\\n\", \"\")\n",
    "        patch[idx][spot[\"label\"][0]][fonduer_sentence_id] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'Company': {'582': 'NetTemps'}, 'Job': {'716': 'Backend Developer'}},\n",
       " '2': {'Job': {'663': 'Java Developer'}, 'Company': {'537': 'NetTemps'}},\n",
       " '90': {'Job': {'941': 'PowerBI Analyst'}, 'Company': {'808': 'NetTemps'}},\n",
       " '100': {'Job': {'917': 'Network Engineer'}, 'Company': {'787': 'NetTemps'}},\n",
       " '8': {'Job': {'710': 'Kurier'}, 'Company': {'583': 'NetTemps'}}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.models import mention_subclass\n",
    "\n",
    "Job = mention_subclass(\"Job\")\n",
    "Company = mention_subclass(\"Company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.matchers import LambdaFunctionMatcher\n",
    "\n",
    "def annotated_job(mention):\n",
    "    doc_id = str(mention.sentence.document.id)\n",
    "    sentence_id = str(mention.sentence.id)\n",
    "    \n",
    "    if doc_id in patch:\n",
    "        if \"Job\" in patch[doc_id].keys():\n",
    "            if sentence_id in patch[doc_id][\"Job\"].keys():\n",
    "                if mention.get_span() == patch[doc_id][\"Job\"][sentence_id]:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def annotated_company(mention):\n",
    "    doc_id = str(mention.sentence.document.id)\n",
    "    sentence_id = str(mention.sentence.id)\n",
    "    \n",
    "    if doc_id in patch:\n",
    "        if \"Company\" in patch[doc_id].keys():\n",
    "            if sentence_id in patch[doc_id][\"Company\"].keys():\n",
    "                if mention.get_span() == patch[doc_id][\"Company\"][sentence_id]:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "job_matcher = LambdaFunctionMatcher(func=annotated_job)\n",
    "company_matcher = LambdaFunctionMatcher(func=annotated_company)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates import MentionNgrams\n",
    "\n",
    "job_ngrams = MentionNgrams(n_max=3, n_min=1)\n",
    "company_ngrams = MentionNgrams(n_max=3, n_min=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates import MentionExtractor\n",
    "\n",
    "mention_extractor = MentionExtractor(\n",
    "    session,\n",
    "    [Job, Company],\n",
    "    [job_ngrams, company_ngrams],\n",
    "    [job_matcher, company_matcher],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-19 10:25:40,005][INFO] fonduer.candidates.mentions:467 - Clearing table: job\n",
      "[2022-04-19 10:25:40,009][INFO] fonduer.candidates.mentions:467 - Clearing table: company\n",
      "[2022-04-19 10:25:40,013][INFO] fonduer.candidates.mentions:475 - Cascading to clear table: presidentname_placeofbirth\n",
      "[2022-04-19 10:25:40,018][INFO] fonduer.utils.udf:67 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013364553451538086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b14c1e8c7214e8ea649919251e2fe9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Mentions: 10 (5 jobs, 5 companies)\n"
     ]
    }
   ],
   "source": [
    "from fonduer.candidates.models import Mention\n",
    "\n",
    "mention_extractor.apply(docs)\n",
    "num_jobs = session.query(Job).count()\n",
    "num_companies = session.query(Company).count()\n",
    "print(\n",
    "    f\"Total Mentions: {session.query(Mention).count()} ({num_jobs} jobs, {num_companies} companies)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.models import candidate_subclass\n",
    "\n",
    "JobCompany = candidate_subclass(\n",
    "    \"PresidentnamePlaceofbirth\", [Job, Company]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates import CandidateExtractor\n",
    "\n",
    "candidate_extractor = CandidateExtractor(session, [JobCompany])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-19 10:25:45,399][INFO] fonduer.candidates.candidates:137 - Clearing table presidentname_placeofbirth (split 0)\n",
      "[2022-04-19 10:25:45,401][INFO] fonduer.utils.udf:67 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012007713317871094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3954f7378b5d43d7a6a1ab76d7fec563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Candidates: 5\n"
     ]
    }
   ],
   "source": [
    "candidate_extractor.apply(docs)\n",
    "print(\n",
    "        f\"Number of Candidates: {session.query(JobCompany).count()}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = session.query(JobCompany).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PresidentnamePlaceofbirth(Job(SpanMention(\"Backend Developer\", sentence=716, chars=[0,16], words=[0,1])), Company(SpanMention(\"NetTemps\", sentence=582, chars=[0,7], words=[0,0])))\n",
      "\n",
      "\n",
      "PresidentnamePlaceofbirth(Job(SpanMention(\"Java Developer\", sentence=663, chars=[0,13], words=[0,1])), Company(SpanMention(\"NetTemps\", sentence=537, chars=[0,7], words=[0,0])))\n",
      "\n",
      "\n",
      "PresidentnamePlaceofbirth(Job(SpanMention(\"Kurier\", sentence=710, chars=[0,5], words=[0,0])), Company(SpanMention(\"NetTemps\", sentence=583, chars=[0,7], words=[0,0])))\n",
      "\n",
      "\n",
      "PresidentnamePlaceofbirth(Job(SpanMention(\"Network Engineer\", sentence=917, chars=[0,15], words=[0,1])), Company(SpanMention(\"NetTemps\", sentence=787, chars=[0,7], words=[0,0])))\n",
      "\n",
      "\n",
      "PresidentnamePlaceofbirth(Job(SpanMention(\"PowerBI Analyst\", sentence=941, chars=[0,14], words=[0,1])), Company(SpanMention(\"NetTemps\", sentence=808, chars=[0,7], words=[0,0])))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in a:\n",
    "    print(c)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7fda46782ee3ee2686cdea5372a2bf51e3d60f2509bba10681b838f36f7f0d4a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('labelstudio-to-fonduer-E7xm7bv1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
