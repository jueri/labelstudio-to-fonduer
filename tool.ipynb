{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  # type: ignore\n",
    "from lxml import etree  # type: ignore\n",
    "import json\n",
    "import os\n",
    "from fonduer.parser.models import Document, Sentence\n",
    "from fonduer.candidates import MentionNgrams\n",
    "from fonduer.candidates import MentionExtractor\n",
    "from fonduer.candidates.models import mention_subclass\n",
    "from fonduer.candidates.matchers import LambdaFunctionMatcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(label_studio_str: str):\n",
    "    split = label_studio_str.split(\"-\")  # strip id\n",
    "    full = \"\".join(split[1:])\n",
    "    split = full.split(\".\")\n",
    "    result = \"\".join(split[:-1])\n",
    "    return result\n",
    "\n",
    "def get_html_tree_from_string(html_string):\n",
    "    soup = BeautifulSoup(html_string)\n",
    "    dom = etree.HTML(str(soup))\n",
    "    root = dom.getroottree()\n",
    "    return root\n",
    "\n",
    "def get_absolute_xpath(rel_xpath, dom):\n",
    "    res = dom.xpath(\"/\"+rel_xpath)[0]\n",
    "    return dom.getpath(res.getparent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_ls_export(export_path, session):\n",
    "    with open(export_path, \"r\") as fin:\n",
    "        export = json.load(fin)\n",
    "    docs = []\n",
    "    relations = []\n",
    "    id_label = {}\n",
    "    for annotated_doc in export:\n",
    "        filename = get_filename(annotated_doc[\"file_upload\"])\n",
    "        fonduer_doc_id = str(session.query(Document.id).filter(Document.name==filename).first()[0])\n",
    "        tree = get_html_tree_from_string(annotated_doc[\"data\"][\"text\"])  # recreate html tree for doc\n",
    "\n",
    "        doc = {}\n",
    "        doc[\"filename\"] = filename\n",
    "        doc[\"fonduer_doc_id\"] = fonduer_doc_id\n",
    "        doc[\"spots\"] = []\n",
    "\n",
    "        for annotations in annotated_doc[\"annotations\"]:\n",
    "            if not annotations[\"result\"]:\n",
    "                continue\n",
    "            for entety in annotations[\"result\"]:\n",
    "                if entety.get(\"value\"):\n",
    "                    xpath_rel = entety[\"value\"][\"start\"]\n",
    "                    xpath_abs = get_absolute_xpath(xpath_rel, tree)\n",
    "                    fd_sentence_id = session.query(Sentence.id).filter(Sentence.document_id==fonduer_doc_id, Sentence.xpath==xpath_abs).first()\n",
    "                    label = entety[\"value\"][\"labels\"][0]\n",
    "                    ls_ID = entety[\"id\"]\n",
    "                    id_label[ls_ID]=label\n",
    "        \n",
    "                    doc[\"spots\"].append({\n",
    "                        # \"xpath_rel\": xpath_rel, \n",
    "                        \"xpath_abs\": xpath_abs,\n",
    "                        \"label\": label, \n",
    "                        \"text\": entety[\"value\"][\"text\"],\n",
    "                        \"ls_ID\": ls_ID,\n",
    "                        \"fd_sentence_id\": fd_sentence_id\n",
    "                        })\n",
    "                else:\n",
    "                    relations.append((entety[\"from_id\"], entety[\"to_id\"], entety[\"labels\"]))\n",
    "            docs.append(doc)\n",
    "    return docs, relations, id_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_relations(relations, id_label):\n",
    "    resolved = []\n",
    "    for relation in relations:\n",
    "        resolved.append((id_label.get(relation[0]), id_label.get(relation[1])))\n",
    "    return set(resolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_ngram_size(export, label):\n",
    "    lengths = []\n",
    "    for doc in export:\n",
    "        for spot in doc[\"spots\"]:\n",
    "            if spot[\"label\"] == label:\n",
    "                lengths.append(len(spot.get(\"text\").split(\" \")))\n",
    "    return MentionNgrams(n_max=max(lengths), n_min=min(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_mention_functions(export):\n",
    "patch = {}\n",
    "for doc in export:\n",
    "    idx = doc[\"fonduer_doc_id\"]\n",
    "    patch[idx]={}\n",
    "    for spot in doc[\"spots\"]:\n",
    "        if spot[\"label\"] not in patch[idx]:\n",
    "            patch[idx][spot[\"label\"]]={}\n",
    "            \n",
    "        fonduer_sentence_id = str(spot[\"fd_sentence_id\"])\n",
    "        text = spot[\"text\"].replace(\"\\\\n\", \"\")\n",
    "        patch[idx][spot[\"label\"]][fonduer_sentence_id] = text\n",
    "#    return patch\n",
    "#create_mention_functions(export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ls_export:\n",
    "    def __init__(self, path, session):\n",
    "        self.export, self.relations, self.id_label = load_ls_export(path, session)\n",
    "        self.session = session\n",
    "        self.relation_types = resolve_relations(self.relations, self.id_label)\n",
    "    \n",
    "    def create_mention_subclasses(self):\n",
    "        self.mention_subclasses = {}\n",
    "        for relation in self.relation_types:\n",
    "            for entety in relation:\n",
    "                if entety not in self.mention_subclasses.keys():\n",
    "                    self.mention_subclasses[entety] = mention_subclass(entety)\n",
    "    \n",
    "    def get_ngram_spaces(self):\n",
    "        self.ngram_spaces = {}\n",
    "        for mention_subclas in self.mention_subclasses:\n",
    "            self.ngram_spaces[mention_subclas] = determine_ngram_size(self.export, mention_subclas)\n",
    "\n",
    "    def create_matching_fuctions(self):\n",
    "        def create_function(spot):\n",
    "            def function_template(mention):\n",
    "                doc_id = str(mention.sentence.document.id)\n",
    "                sentence_id = str(mention.sentence.id)\n",
    "                \n",
    "                if doc_id in patch:\n",
    "                    if spot in patch[doc_id].keys():\n",
    "                        if sentence_id in patch[doc_id][spot].keys():\n",
    "                            if mention.get_span() == patch[doc_id][spot][sentence_id]:\n",
    "                                return True\n",
    "                return False\n",
    "            return function_template\n",
    "\n",
    "        self.matching_fuctions = {}\n",
    "        for mention_subclas in self.mention_subclasses:\n",
    "            function = create_function(mention_subclas)\n",
    "            self.matching_fuctions[mention_subclas] = LambdaFunctionMatcher(func=function)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    # def create_mention_extractors(self):\n",
    "    #     self.mention_extractors = []\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #         mention_extractor = MentionExtractor(\n",
    "    #             session,\n",
    "    #             [Job, Company],\n",
    "    #             [job_ngrams, company_ngrams],\n",
    "    #             [job_matcher, company_matcher],\n",
    "    #         )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"data\"\n",
    "export_dir = os.path.join(base_dir, \"export\")\n",
    "export_path = os.path.join(export_dir, \"export_1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-19 12:27:31,060][INFO] fonduer.meta:49 - Setting logging directory to: logs/2022-04-19_12-27-31\n",
      "[2022-04-19 12:27:31,071][INFO] fonduer.meta:134 - Connecting user:user to 127.0.0.1:8001/jobs_companie\n",
      "[2022-04-19 12:27:31,139][INFO] fonduer.meta:162 - Initializing the storage schema\n"
     ]
    }
   ],
   "source": [
    "from fonduer import Meta, init_logging\n",
    "\n",
    "ATTRIBUTE = \"jobs_companie\"\n",
    "conn_string = 'postgresql://user@127.0.0.1:8001/' + ATTRIBUTE\n",
    "\n",
    "# Configure logging for Fonduer\n",
    "init_logging(log_dir=\"logs\")\n",
    "\n",
    "session = Meta.init(conn_string).Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = ls_export(export_path, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "export.create_mention_subclasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Company': fonduer.candidates.models.mention.Company,\n",
       " 'Job': fonduer.candidates.models.mention.Job}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export.mention_subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "export.get_ngram_spaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fonduer.candidates.mentions.MentionNgrams at 0x7fbaff0bb940>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export.ngram_spaces[\"Company\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "export.create_matching_fuctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Company': <fonduer.candidates.matchers.LambdaFunctionMatcher at 0x7fbaff0bbca0>,\n",
       " 'Job': <fonduer.candidates.matchers.LambdaFunctionMatcher at 0x7fbaff0bbfd0>}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export.matching_fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7fda46782ee3ee2686cdea5372a2bf51e3d60f2509bba10681b838f36f7f0d4a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('labelstudio-to-fonduer-E7xm7bv1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
